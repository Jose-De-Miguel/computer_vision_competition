{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13943031,"sourceType":"datasetVersion","datasetId":8886325}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T13:00:21.038076Z","iopub.execute_input":"2025-12-07T13:00:21.038417Z","iopub.status.idle":"2025-12-07T13:00:21.184965Z","shell.execute_reply.started":"2025-12-07T13:00:21.038394Z","shell.execute_reply":"2025-12-07T13:00:21.183681Z"}},"outputs":[{"name":"stdout","text":"models\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch, torchvision\nprint(torch.__version__, torchvision.__version__)\nprint(\"CUDA available:\", torch.cuda.is_available())\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T13:09:38.434594Z","iopub.execute_input":"2025-12-07T13:09:38.435071Z","iopub.status.idle":"2025-12-07T13:09:49.149645Z","shell.execute_reply.started":"2025-12-07T13:09:38.435043Z","shell.execute_reply":"2025-12-07T13:09:49.148581Z"}},"outputs":[{"name":"stdout","text":"2.6.0+cu124 0.21.0+cu124\nCUDA available: False\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import json\nimport numpy as np\nimport uuid\n\n\nclass GenericObject:\n    \"\"\"\n    Generic object data.\n    \"\"\"\n    def __init__(self):\n        self.id = uuid.uuid4()\n        self.bb = (-1, -1, -1, -1)\n        self.category= -1\n        self.score = -1\n\nclass GenericImage:\n    \"\"\"\n    Generic image data.\n    \"\"\"\n    def __init__(self, filename):\n        self.filename = filename\n        self.tile = np.array([-1, -1, -1, -1])  # (pt_x, pt_y, pt_x+width, pt_y+height)\n        self.objects = list([])\n\n    def add_object(self, obj: GenericObject):\n        self.objects.append(obj)\n\ncategories = {0: 'Small car', 1: 'Bus', 2: 'Truck', 3: 'Building'}\n\njson_file = '/kaggle/input/xview-detection/xview_det_train.json'\nwith open(json_file) as ifs:\n    json_data = json.load(ifs)\n\ncounts = dict.fromkeys(categories.values(), 0)\nanns = []\nfor json_img in json_data['images'].values():\n    image = GenericImage(json_img['filename'])\n    image.tile = np.array([0, 0, json_img['width'], json_img['height']])\n    for json_ann in [elem for elem in json_data['annotations'].values()\n                     if elem['image_id'] == json_img['image_id']]:\n        obj = GenericObject()\n        obj.id = json_ann['image_id']\n        obj.bb = (\n            int(json_ann['bbox'][0]),\n            int(json_ann['bbox'][1]),\n            int(json_ann['bbox'][2]),\n            int(json_ann['bbox'][3]),\n        )\n        obj.category = json_ann['category_id']\n        counts[obj.category] += 1\n        image.add_object(obj)\n    anns.append(image)\n\nprint(counts)\n\nfrom sklearn.model_selection import train_test_split\n\nanns_train, anns_valid = train_test_split(\n    anns, test_size=0.1, random_state=1, shuffle=True\n)\n\n\n# Map category_id -> 0-based index\ncatid_to_idx = {cat_id: i for i, cat_id in categories.items()}\nnum_classes = len(catid_to_idx)\n\ndef build_torch_annotations(anns, catid_to_idx):\n    torch_anns = []\n    for img_ann in anns:\n        boxes = []\n        labels = []\n        for obj in img_ann.objects:\n            boxes.append(list(obj.bb))  # [x1, y1, x2, y2]\n            cls_idx = catid_to_idx[obj.category]   # 0..num_classes-1\n            labels.append(cls_idx + 1)             # 1..num_classes (0 = background)\n        torch_anns.append({\n            \"file_name\": img_ann.filename,\n            \"boxes\": boxes,\n            \"labels\": labels,\n        })\n    return torch_anns\n\ntrain_annotations = build_torch_annotations(anns_train, catid_to_idx)\nvalid_annotations = build_torch_annotations(anns_valid, catid_to_idx)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:06:57.165752Z","iopub.execute_input":"2025-12-07T15:06:57.166038Z","iopub.status.idle":"2025-12-07T15:12:26.479141Z","shell.execute_reply.started":"2025-12-07T15:06:57.166018Z","shell.execute_reply":"2025-12-07T15:12:26.478589Z"}},"outputs":[{"name":"stdout","text":"{'Small car': 188300, 'Bus': 6269, 'Truck': 10600, 'Building': 275943}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as T\n\nclass MyDetectionDataset(Dataset):\n    def __init__(self, annotations, image_dir=\"\", transforms=None):\n        self.annotations = annotations\n        self.image_dir = image_dir\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, idx):\n        ann = self.annotations[idx]\n        file_name = ann[\"file_name\"]\n\n        if os.path.isabs(file_name) or self.image_dir == \"\":\n            img_path = file_name\n        else:\n            img_path = os.path.join(self.image_dir, file_name)\n\n        img = Image.open(img_path).convert(\"RGB\")\n\n        boxes = torch.as_tensor(ann[\"boxes\"], dtype=torch.float32)\n        labels = torch.as_tensor(ann[\"labels\"], dtype=torch.int64)\n\n        # ðŸ”§ Filter out degenerate (zero / negative width or height) boxes\n        if boxes.numel() > 0:\n            x1 = boxes[:, 0]\n            y1 = boxes[:, 1]\n            x2 = boxes[:, 2]\n            y2 = boxes[:, 3]\n\n            #discard boxes with zero height or width \n            keep = (x2 > x1) & (y2 > y1)\n            boxes = boxes[keep]\n            labels = labels[keep]\n\n        # if everything got filtered, still return empty tensors (allowed)\n        if boxes.numel() == 0:\n            boxes = torch.zeros((0, 4), dtype=torch.float32)\n            labels = torch.zeros((0,), dtype=torch.int64)\n\n        target = {\n            \"boxes\": boxes,\n            \"labels\": labels,\n            \"image_id\": torch.tensor([idx]),\n        }\n\n        if self.transforms is not None:\n            img = self.transforms(img)\n\n        return img, target\n\n\ntrain_tfms = T.Compose([T.ToTensor()])\nval_tfms = T.Compose([T.ToTensor()])\n\nimage_root = \"/kaggle/input/xview-detection\" \n\ntrain_dataset = MyDetectionDataset(train_annotations, image_dir=image_root, transforms=train_tfms)\nvalid_dataset = MyDetectionDataset(valid_annotations, image_dir=image_root, transforms=val_tfms)\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True,\n                          num_workers=2, collate_fn=collate_fn)\nvalid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False,\n                          num_workers=2, collate_fn=collate_fn)\n\ndef compute_discard_stats(annotations):\n    total = len(annotations)\n    discarded = 0\n    total_boxes = 0\n    discarded_boxes = 0\n\n    for ann in annotations:\n        valid = 0\n        for (x1, y1, x2, y2) in ann[\"boxes\"]:\n            total_boxes += 1\n            if x2 > x1 and y2 > y1:\n                valid += 1\n            else:\n                discarded_boxes += 1\n\n        if valid == 0:\n            discarded += 1\n\n    return {\n        \"total_images\": total,\n        \"images_discarded\": discarded,\n        \"images_discarded_pct\": 100 * discarded / total,\n        \"total_boxes\": total_boxes,\n        \"boxes_discarded\": discarded_boxes,\n        \"boxes_discarded_pct\": 100 * discarded_boxes / total_boxes if total_boxes > 0 else 0,\n    }\n\ntrain_stats = compute_discard_stats(train_annotations)\nvalid_stats = compute_discard_stats(valid_annotations)\n\ntrain_stats, valid_stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:23:42.137221Z","iopub.execute_input":"2025-12-07T15:23:42.137523Z","iopub.status.idle":"2025-12-07T15:23:42.224820Z","shell.execute_reply.started":"2025-12-07T15:23:42.137500Z","shell.execute_reply":"2025-12-07T15:23:42.224217Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"({'total_images': 6845,\n  'images_discarded': 0,\n  'images_discarded_pct': 0.0,\n  'total_boxes': 433210,\n  'boxes_discarded': 7,\n  'boxes_discarded_pct': 0.0016158445095911913},\n {'total_images': 761,\n  'images_discarded': 0,\n  'images_discarded_pct': 0.0,\n  'total_boxes': 47902,\n  'boxes_discarded': 0,\n  'boxes_discarded_pct': 0.0})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import torchvision\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n\nnum_classes = len(catid_to_idx) + 1  # +1 for background\nin_features = model.roi_heads.box_predictor.cls_score.in_features\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:25:49.664913Z","iopub.execute_input":"2025-12-07T15:25:49.665472Z","iopub.status.idle":"2025-12-07T15:25:50.341478Z","shell.execute_reply.started":"2025-12-07T15:25:49.665445Z","shell.execute_reply":"2025-12-07T15:25:50.340873Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"FasterRCNN(\n  (transform): GeneralizedRCNNTransform(\n      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n  )\n  (backbone): BackboneWithFPN(\n    (body): IntermediateLayerGetter(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): FrozenBatchNorm2d(256, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(512, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(1024, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(2048, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (fpn): FeaturePyramidNetwork(\n      (inner_blocks): ModuleList(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (layer_blocks): ModuleList(\n        (0-3): 4 x Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (extra_blocks): LastLevelMaxPool()\n    )\n  )\n  (rpn): RegionProposalNetwork(\n    (anchor_generator): AnchorGenerator()\n    (head): RPNHead(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n      )\n      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (roi_heads): RoIHeads(\n    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n    (box_head): TwoMLPHead(\n      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNPredictor(\n      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n    )\n  )\n)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"best_loss = float(\"inf\")\nbest_epoch = -1\n\nhistory = {\n    \"loss\": [],\n    \"loss_classifier\": [],\n    \"loss_box_reg\": [],\n    \"loss_objectness\": [],\n    \"loss_rpn_box_reg\": [],\n}\n\nfor epoch in range(num_epochs):\n    model.train()\n    \n    epoch_loss = 0.0\n    loss_classifier = 0.0\n    loss_box_reg = 0.0\n    loss_objectness = 0.0\n    loss_rpn_box_reg = 0.0\n\n    for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n        images = [img.to(device) for img in images]\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        loss_dict = model(images, targets)\n        loss = sum(loss for loss in loss_dict.values())\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        loss_classifier += loss_dict[\"loss_classifier\"].item()\n        loss_box_reg += loss_dict[\"loss_box_reg\"].item()\n        loss_objectness += loss_dict[\"loss_objectness\"].item()\n        loss_rpn_box_reg += loss_dict[\"loss_rpn_box_reg\"].item()\n\n    lr_scheduler.step()\n\n    # Promedios por epoch\n    epoch_loss /= len(train_loader)\n    history[\"loss\"].append(epoch_loss)\n    history[\"loss_classifier\"].append(loss_classifier / len(train_loader))\n    history[\"loss_box_reg\"].append(loss_box_reg / len(train_loader))\n    history[\"loss_objectness\"].append(loss_objectness / len(train_loader))\n    history[\"loss_rpn_box_reg\"].append(loss_rpn_box_reg / len(train_loader))\n\n    print(f\"Epoch {epoch+1} â€” loss: {epoch_loss:.4f}\")\n\n    # GUARDAR EL MEJOR MODELO\n    if epoch_loss < best_loss:\n        best_loss = epoch_loss\n        best_epoch = epoch + 1\n        \n        torch.save(model.state_dict(), \"/kaggle/working/best_model_weights.pth\")\n\n        print(f\"Nuevo mejor modelo guardado en epoch {epoch+1} (loss={best_loss:.4f})\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:25:57.610852Z","iopub.execute_input":"2025-12-07T15:25:57.611539Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 1/10:   0%|          | 0/3423 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"915ee9cafc924890a0d0999e45cda5f1"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 loss: 1.1190\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10:   0%|          | 0/3423 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"176ab2f842ca4a7f96274b39e3f6579a"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n        self._shutdown_workers()self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nif w.is_alive():    \n if w.is_alive(): \n          ^ ^ ^^^^^^^^^^^^^Exception ignored in: Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480><function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^^\n^\n^^^Traceback (most recent call last):\n\n^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n          File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\nassert self._parent_pid == os.getpid(), 'can only test a child process'    self._shutdown_workers()    \nself._shutdown_workers()\nassert self._parent_pid == os.getpid(), 'can only test a child process'\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n           if w.is_alive():  if w.is_alive():\n  \n                            ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    ^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n\n^^  ^^  ^^  ^^   ^^  ^^ ^ ^^  ^^  ^^  ^^  ^^ ^^^^^^^^^^^^^\n^^AssertionError^^^: ^^^can only test a child process^^\n^^\nAssertionError^^: ^^^can only test a child process^\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^AssertionError: ^can only test a child process\n^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 loss: 1.0044\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10:   0%|          | 0/3423 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b14b8608439c4730bb05a5121b4da353"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>\nException ignored in: Traceback (most recent call last):\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n\n    self._shutdown_workers()Traceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nself._shutdown_workers()    \nif w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n      if w.is_alive():   \n   ^ ^ ^ ^ ^  ^^^^^^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^\n^^Traceback (most recent call last):\n^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^self._shutdown_workers()    \n^Exception ignored in: ^assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n\n ^     \nTraceback (most recent call last):\nif w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n \n         assert self._parent_pid == os.getpid(), 'can only test a child process' self._shutdown_workers()  \n\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n         if w.is_alive():    \n     ^  ^ ^^  ^ ^ ^ ^  ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^^^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n^^^^     ^^ ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n^ ^ ^^ ^  ^^  ^ ^  ^^ ^ ^  ^^^   ^ ^ ^^^\n^^^^AssertionError^^^: ^^^^^can only test a child process^^^\n\n^^AssertionError^: ^^Exception ignored in: can only test a child process^^^^\n^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^^^\n^^Exception ignored in: Traceback (most recent call last):\n^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^\n^    Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^self._shutdown_workers()^^    \n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^self._shutdown_workers()\n    ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^if w.is_alive():^^    ^^^\nif w.is_alive():^^  ^\n ^  ^^   ^ ^  ^^ ^\n ^ ^^AssertionError^: ^^\nAssertionErrorcan only test a child process^: \n^can only test a child process^^\nException ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^^Exception ignored in: ^\n^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>Traceback (most recent call last):\n^^^\nTraceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    ^^    self._shutdown_workers()self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n^if w.is_alive():      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\nif w.is_alive():\n\n\n      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  assert self._parent_pid == os.getpid(), 'can only test a child process'      \n   assert self._parent_pid == os.getpid(), 'can only test a child process'  \n          ^  ^   ^^ ^^^ ^ ^^ ^  ^^  ^^ ^^^ ^^^ ^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n ^^^    ^^\n^assert self._parent_pid == os.getpid(), 'can only test a child process'^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n ^    ^^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^\n ^  ^ ^^  ^^  ^ ^^  ^ ^ ^  ^  ^^^^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^AssertionError^^^: ^^^can only test a child process^^\n^^^^^^^^^^^^\n^^AssertionError^^: ^^^^can only test a child process^^^^\n^^^^^^^^^^\nAssertionError^^: ^can only test a child process\n\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 loss: 0.9697\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10:   0%|          | 0/3423 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cca287fd473145caa751e376d718c797"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480><function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>\n\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n        self._shutdown_workers()self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n    if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n     if w.is_alive(): \n         ^ ^  ^^Exception ignored in: ^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^^\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^Traceback (most recent call last):\n^\n^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    ^    self._shutdown_workers()^self._shutdown_workers()^\n\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^        ^\nif w.is_alive():^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\nif w.is_alive():\n\n^     ^   assert self._parent_pid == os.getpid(), 'can only test a child process'\n  \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n           assert self._parent_pid == os.getpid(), 'can only test a child process'   \n  ^ ^ ^  ^^ ^ ^ ^ ^ ^ ^ ^^ ^ ^^^^ ^^^ ^ ^^^^^ ^^^^\n^\n^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n\n^  ^^^   ^^  ^^ ^ ^^  ^ ^^^^ ^  ^^^  ^ ^  ^^^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^AssertionError^: ^^can only test a child process^^^^\n^^^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>\n^\n^AssertionError^^Traceback (most recent call last):\n: ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\ncan only test a child process^^\n    ^^self._shutdown_workers()Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^\n^    Traceback (most recent call last):\n^^^if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^\n    self._shutdown_workers()^^  \n^^^^   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^     ^^ if w.is_alive():^ ^\n ^^ \n^  \nAssertionError^:  ^AssertionErrorcan only test a child process ^ \n: ^ ^can only test a child process^Exception ignored in: ^^\n^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^\n^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^Traceback (most recent call last):\n^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^Traceback (most recent call last):\n^    ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\nself._shutdown_workers()    ^\n\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nself._shutdown_workers()^        \n\nassert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nif w.is_alive():  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n\n            assert self._parent_pid == os.getpid(), 'can only test a child process' if w.is_alive():  \n \n           ^ ^   ^ ^  ^    ^ ^   ^ ^^^ ^^^^^^^^^^^^^^^^^\n^^^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n^^^ ^^^ ^^ \n^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^ ^^ assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^\n  ^ ^^^ ^^ ^^ ^ ^^  ^^  ^^^ ^^^ ^^^^ ^^^^ ^^^ ^^^\n ^AssertionError^^^^: ^^^can only test a child process\n^AssertionError^^\n^^^: ^^can only test a child process^^Exception ignored in: \n^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>\n^^^Traceback (most recent call last):\nException ignored in:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^    ^\n^self._shutdown_workers()Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n        self._shutdown_workers()^^^if w.is_alive():\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^\n^    ^ ^if w.is_alive(): ^\n^^^  ^^  ^ ^^ ^ ^ ^  ^^ ^^ ^^\n^^AssertionError^^^^: can only test a child process^^^^\n^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>^^\n\n^AssertionErrorTraceback (most recent call last):\n^^: ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^can only test a child process    ^\n^self._shutdown_workers()^\n\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nException ignored in:       File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7e5485572480>    if w.is_alive():\nassert self._parent_pid == os.getpid(), 'can only test a child process'    \n\nassert self._parent_pid == os.getpid(), 'can only test a child process'  Traceback (most recent call last):\n \n     File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n         self._shutdown_workers()   \n     File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^ ^      ^ if w.is_alive():  ^\n^  ^   ^ ^^  ^^  ^^^ ^^^ ^^^ ^^^^^^^\n^^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^^^ ^^^ ^^^^^ ^^^^ ^^ ^^^^ ^^^ ^^^ ^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^ ^     ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n ^ ^^ ^^^ ^^^ ^^^^ ^^ ^^ ^^^ \n^ AssertionError^ : ^^ can only test a child process^\n^\nAssertionError: ^^can only test a child process^^^^\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^AssertionError^: ^can only test a child process\n\nAssertionError: can only test a child process\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(\"\\nEntrenamiento finalizado.\")\nprint(f\"Mejor epoch: {best_epoch} con loss={best_loss:.4f}\")\n\n# Cargar el mejor modelo\nmodel.load_state_dict(torch.load(\"/kaggle/working/best_model_weights.pth\", map_location=device))\nmodel.to(device)\nmodel.eval()\n\nprint(\"âœ” Mejor modelo cargado correctamente.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/working/FasterRCNN-history.json\", \"w\") as f:\n    json.dump(history, f)\n\n\ntorch.save(model, \"/kaggle/working/FasterRCNN-full.pth\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.colors as col\nimport numpy as np\n%matplotlib inline\n\ndef area_intersection(boxes, box):\n    xmin = np.maximum(np.min(boxes[:, 0::2], axis=1), np.min(box[0::2]))\n    ymin = np.maximum(np.min(boxes[:, 1::2], axis=1), np.min(box[1::2]))\n    xmax = np.minimum(np.max(boxes[:, 0::2], axis=1), np.max(box[0::2]))\n    ymax = np.minimum(np.max(boxes[:, 1::2], axis=1), np.max(box[1::2]))\n    w = np.maximum(xmax - xmin + 1.0, 0.0)\n    h = np.maximum(ymax - ymin + 1.0, 0.0)\n    return w * h\n\ndef area_union(boxes, box):\n    area_anns = (np.max(box[0::2])-np.min(box[0::2])+1.0) * (np.max(box[1::2])-np.min(box[1::2])+1.0)\n    area_pred = (np.max(boxes[:, 0::2], axis=1)-np.min(boxes[:, 0::2], axis=1)+1.0) * (np.max(boxes[:, 1::2], axis=1)-np.min(boxes[:, 1::2], axis=1)+1.0)\n    return area_anns + area_pred - area_intersection(boxes, box)\n\ndef calc_iou(boxes, box):\n    iou = area_intersection(boxes, box) / area_union(boxes, box)\n    max_value = np.max(iou)\n    max_index = np.argmax(iou)\n    return max_value, max_index\n\ndef calc_ap(rec, prec):\n    # First append sentinel values at the end\n    mrec = np.concatenate(([0.0], rec, [1.0]))\n    mpre = np.concatenate(([0.0], prec, [0.0]))\n    # Compute the precision envelope\n    for i in range(mpre.size-1, 0, -1):\n        mpre[i-1] = np.maximum(mpre[i-1], mpre[i])\n    # To calculate area under PR curve, look for points where X axis (recall) changes value\n    i = np.where(mrec[1:] != mrec[:-1])[0]\n    # and sum (\\Delta recall) * prec\n    ap = np.sum((mrec[i+1] - mrec[i]) * mpre[i+1])\n    return ap\n\ndef draw_confusion_matrix(cm, categories):\n    # Draw confusion matrix\n    fig = plt.figure(figsize=[6.4*pow(len(categories), 0.5), 4.8*pow(len(categories), 0.5)])\n    ax = fig.add_subplot(111)\n    cm = cm.astype('float') / np.maximum(cm.sum(axis=1)[:, np.newaxis], np.finfo(np.float64).eps)\n    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.get_cmap('Blues'))\n    ax.figure.colorbar(im, ax=ax)\n    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), xticklabels=categories, yticklabels=categories, ylabel='Annotation', xlabel='Prediction')\n    # Rotate the tick labels and set their alignment\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    # Loop over data dimensions and create text annotations\n    thresh = cm.max() / 2.0\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], '.2f'), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\", fontsize=int(20-pow(len(categories), 0.5)))\n    fig.tight_layout()\n    plt.show()\n\ndef draw_precision_recall(precisions, recalls, categories):\n    # Draw precision-recall curves for each category\n    fig = plt.figure(figsize=[6.4*pow(len(categories), 0.5), 4.8*pow(len(categories), 0.5)])\n    ax = fig.add_subplot(111)\n    plt.axis([0, 1, 0, 1])\n    c_dark = list(filter(lambda x: x.startswith('dark'), col.cnames.keys()))\n    aps = []\n    # Compare categories for a specific algorithm\n    for idx in range(len(categories)):\n        plt.plot(recalls[idx], precisions[idx], color=c_dark[idx], label=categories[idx], linewidth=4.0)\n        aps.append(calc_ap(recalls[idx], precisions[idx]))\n    handles, labels = ax.get_legend_handles_labels()\n    labels = [str(val + ' [' + \"{:.3f}\".format(aps[idx]) + ']') for idx, val in enumerate(labels)]\n    handles = [h for (ap, h) in sorted(zip(aps, handles), key=lambda x: x[0], reverse=True)]\n    labels = [l for (ap, l) in sorted(zip(aps, labels), key=lambda x: x[0], reverse=True)]\n    leg = plt.legend(handles, labels, loc='upper right')\n    leg.set_zorder(100)\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.grid(\"on\", linestyle=\"--\", linewidth=2.0)\n    fig.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom tqdm.auto import tqdm\n\nnum_classes = len(catid_to_idx)  # SIN incluir background\ncm = np.zeros((num_classes, num_classes), dtype=np.int64)  # [gt, pred]\n\niou_thresh = 0.5\nscore_thresh = 0.5   # solo consideramos predicciones con score >= score_thresh\n\nmodel.eval()\n\nwith torch.no_grad():\n    for img, target in tqdm(valid_loader, desc=\"Evaluating\"):\n        # valid_loader devuelve batch -> listas\n        img = [i.to(device) for i in img]\n        outputs = model(img)\n\n        # solo batch_size=1 para simplificar\n        output = outputs[0]\n        gt = target[0]\n\n        gt_boxes = gt[\"boxes\"].cpu().numpy()\n        gt_labels = gt[\"labels\"].cpu().numpy() - 1  # labels 1..C -> 0..C-1\n\n        pred_boxes = output[\"boxes\"].cpu().numpy()\n        pred_scores = output[\"scores\"].cpu().numpy()\n        pred_labels = output[\"labels\"].cpu().numpy() - 1  # 0..C-1\n\n        # filtrar por score\n        keep = pred_scores >= score_thresh\n        pred_boxes = pred_boxes[keep]\n        pred_labels = pred_labels[keep]\n\n        # para cada GT, buscamos la pred con mayor IoU\n        matched_pred = set()\n        for gt_box, gt_label in zip(gt_boxes, gt_labels):\n            if len(pred_boxes) == 0:\n                continue\n\n            iou_vals = area_intersection(pred_boxes, gt_box) / area_union(pred_boxes, gt_box)\n            best_idx = np.argmax(iou_vals)\n            best_iou = iou_vals[best_idx]\n\n            if best_iou >= iou_thresh:\n                pl = int(pred_labels[best_idx])\n                gl = int(gt_label)\n                cm[gl, pl] += 1\n                matched_pred.add(best_idx)\n            # si no supera el threshold, se podrÃ­a contar como FN del gt (no entra en matriz porque no hay pred)\n\n\ncategory_names = list(catid_to_idx.keys())  # o el orden que uses en el label map\n\n# OJO: catid_to_idx es dict {cat_id -> idx} asÃ­ que mejor construir lista ordenada\ninv_map = {v: k for k, v in catid_to_idx.items()}\ncategory_names = [str(inv_map[i]) for i in range(num_classes)]\n\ndraw_confusion_matrix(cm, category_names)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_pr_curves(model, dataset, device, iou_thresh=0.5, score_thresh=0.0):\n    model.eval()\n    num_classes = len(catid_to_idx)\n\n    # por clase: listas de (score, is_tp)\n    class_scores = [[] for _ in range(num_classes)]\n    class_tp = [[] for _ in range(num_classes)]\n    class_total_gt = [0 for _ in range(num_classes)]\n\n    with torch.no_grad():\n        for i in tqdm(range(len(dataset)), desc=\"PR eval\"):\n            img, target = dataset[i]\n            img_gpu = img.to(device)\n            pred = model([img_gpu])[0]\n\n            gt_boxes = target[\"boxes\"].numpy()\n            gt_labels = target[\"labels\"].numpy() - 1      # 0..C-1\n            pred_boxes = pred[\"boxes\"].cpu().numpy()\n            pred_scores = pred[\"scores\"].cpu().numpy()\n            pred_labels = pred[\"labels\"].cpu().numpy() - 1\n\n            # contar GTs por clase\n            for gl in gt_labels:\n                class_total_gt[int(gl)] += 1\n\n            # filtrar por score\n            keep = pred_scores >= score_thresh\n            pred_boxes = pred_boxes[keep]\n            pred_scores = pred_scores[keep]\n            pred_labels = pred_labels[keep]\n\n            # marcar GTs como no usados aÃºn\n            used_gt = np.zeros(len(gt_boxes), dtype=bool)\n\n            # ordenar predicciones por score desc\n            order = np.argsort(-pred_scores)\n            pred_boxes = pred_boxes[order]\n            pred_scores = pred_scores[order]\n            pred_labels = pred_labels[order]\n\n            # para cada pred, ver si es TP o FP\n            for pb, ps, pl in zip(pred_boxes, pred_scores, pred_labels):\n                if len(gt_boxes) == 0:\n                    class_scores[pl].append(ps)\n                    class_tp[pl].append(0)\n                    continue\n\n                ious = area_intersection(gt_boxes, pb) / area_union(gt_boxes, pb)\n                best_gt = np.argmax(ious)\n                best_iou = ious[best_gt]\n\n                if best_iou >= iou_thresh and (not used_gt[best_gt]) and (pl == gt_labels[best_gt]):\n                    used_gt[best_gt] = True\n                    class_scores[pl].append(ps)\n                    class_tp[pl].append(1)   # TP\n                else:\n                    class_scores[pl].append(ps)\n                    class_tp[pl].append(0)   # FP\n\n    # ahora calculamos precision/recall por clase\n    precisions = []\n    recalls = []\n\n    for c in range(num_classes):\n        if len(class_scores[c]) == 0 or class_total_gt[c] == 0:\n            precisions.append(np.array([0.0]))\n            recalls.append(np.array([0.0]))\n            continue\n\n        # ordenar por score otra vez por si acaso\n        order = np.argsort(-np.array(class_scores[c]))\n        tp = np.array(class_tp[c])[order]\n        fp = 1 - tp\n\n        tp_cum = np.cumsum(tp)\n        fp_cum = np.cumsum(fp)\n\n        rec = tp_cum / class_total_gt[c]\n        prec = tp_cum / np.maximum(tp_cum + fp_cum, np.finfo(np.float64).eps)\n\n        precisions.append(prec)\n        recalls.append(rec)\n\n    return precisions, recalls\n\nprecisions, recalls = compute_pr_curves(model, valid_dataset, device)\n\n# nombres de clases (mismo orden que catid_to_idx)\ninv_map = {v: k for k, v in catid_to_idx.items()}\ncategory_names = [str(inv_map[i]) for i in range(len(catid_to_idx))]\n\ndraw_precision_recall(precisions, recalls, category_names)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}